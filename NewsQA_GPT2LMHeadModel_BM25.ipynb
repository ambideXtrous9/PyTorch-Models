{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfYGPbI77os7",
        "outputId": "458bd0b6-7cef-45c4-da8b-29a1f449627e",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:10:55.851088Z",
          "iopub.execute_input": "2023-01-29T18:10:55.852493Z",
          "iopub.status.idle": "2023-01-29T18:10:56.994341Z",
          "shell.execute_reply.started": "2023-01-29T18:10:55.852445Z",
          "shell.execute_reply": "2023-01-29T18:10:56.993162Z"
        },
        "trusted": true
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb  2 09:44:33 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    31W /  70W |   1318MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1993      C                                    1315MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install --quiet pytorch-lightning\n",
        "!pip install --quiet tokenizers\n",
        "!pip install --quiet torch\n",
        "!pip install --quiet rank-bm25"
      ],
      "metadata": {
        "id": "BOGVLURH7teO",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:10:56.998830Z",
          "iopub.execute_input": "2023-01-29T18:10:56.999157Z",
          "iopub.status.idle": "2023-01-29T18:11:37.328156Z",
          "shell.execute_reply.started": "2023-01-29T18:10:56.999126Z",
          "shell.execute_reply": "2023-01-29T18:11:37.326943Z"
        },
        "trusted": true
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import packages**"
      ],
      "metadata": {
        "id": "jrg7sueI-Yac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored\n",
        "import textwrap\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from rank_bm25 import BM25Okapi\n",
        "from transformers import (\n",
        "    AdamW,GPT2LMHeadModel, GPT2Tokenizer as Tokenizer)"
      ],
      "metadata": {
        "id": "LRtGwHJ38MdG",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:37.329933Z",
          "iopub.execute_input": "2023-01-29T18:11:37.330678Z",
          "iopub.status.idle": "2023-01-29T18:11:48.245964Z",
          "shell.execute_reply.started": "2023-01-29T18:11:37.330620Z",
          "shell.execute_reply": "2023-01-29T18:11:48.244811Z"
        },
        "trusted": true
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything (42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "f5wjWNJa9NS0",
        "outputId": "fdaff5a3-481c-46d8-c15b-aff875207dce",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:48.247696Z",
          "iopub.execute_input": "2023-01-29T18:11:48.248460Z",
          "iopub.status.idle": "2023-01-29T18:11:48.261637Z",
          "shell.execute_reply.started": "2023-01-29T18:11:48.248417Z",
          "shell.execute_reply": "2023-01-29T18:11:48.260318Z"
        },
        "trusted": true
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-91c7b3c14fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed_everything\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lightning_fabric/utilities/seed.py\u001b[0m in \u001b[0;36mseed_everything\u001b[0;34m(seed, workers)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: false INTERNAL ASSERT FAILED at \"../c10/cuda/CUDAGraphsC10Utils.h\":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32765"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset**"
      ],
      "metadata": {
        "id": "ZW8NFj2v_vMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ePjLzHoyC1qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/MTP CODE/NewsQA_SPAN.feather'"
      ],
      "metadata": {
        "id": "lNVnF2Ox-XW3",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:48.266678Z",
          "iopub.execute_input": "2023-01-29T18:11:48.267309Z",
          "iopub.status.idle": "2023-01-29T18:11:48.271679Z",
          "shell.execute_reply.started": "2023-01-29T18:11:48.267270Z",
          "shell.execute_reply": "2023-01-29T18:11:48.270682Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_feather(path)\n",
        "df"
      ],
      "metadata": {
        "id": "VAKoobAp-w2T",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:48.273217Z",
          "iopub.execute_input": "2023-01-29T18:11:48.274016Z",
          "iopub.status.idle": "2023-01-29T18:11:50.330411Z",
          "shell.execute_reply.started": "2023-01-29T18:11:48.273978Z",
          "shell.execute_reply": "2023-01-29T18:11:50.329362Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:5000]"
      ],
      "metadata": {
        "id": "-sPYt2X90rYb",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:50.331881Z",
          "iopub.execute_input": "2023-01-29T18:11:50.333908Z",
          "iopub.status.idle": "2023-01-29T18:11:50.338843Z",
          "shell.execute_reply.started": "2023-01-29T18:11:50.333865Z",
          "shell.execute_reply": "2023-01-29T18:11:50.337681Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "QtmR_cUM_pVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = df['paragraph'].tolist()\n",
        "tokenized_corpus = [doc.lower().split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ],
      "metadata": {
        "id": "u_MDp56teweM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'gpt2'"
      ],
      "metadata": {
        "id": "N73_9CLJ-0a6",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:50.340410Z",
          "iopub.execute_input": "2023-01-29T18:11:50.341116Z",
          "iopub.status.idle": "2023-01-29T18:11:50.350612Z",
          "shell.execute_reply.started": "2023-01-29T18:11:50.341078Z",
          "shell.execute_reply": "2023-01-29T18:11:50.349746Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ],
      "metadata": {
        "id": "l1fNyhiw_3di",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:50.351756Z",
          "iopub.execute_input": "2023-01-29T18:11:50.353475Z",
          "iopub.status.idle": "2023-01-29T18:11:52.498602Z",
          "shell.execute_reply.started": "2023-01-29T18:11:50.353434Z",
          "shell.execute_reply": "2023-01-29T18:11:52.497407Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NQADataset(Dataset):\n",
        "  def __init__(self,data : pd.DataFrame,tokenizer : Tokenizer,source_max_token_len : int = 400,target_max_token_len : int = 32):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.source_max_token_len = source_max_token_len\n",
        "    self.target_max_token_len = target_max_token_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self,index : int):\n",
        "    data_row = self.data.iloc[index]\n",
        "\n",
        "    ques = data_row['question']\n",
        "    scores = bm25.get_scores(ques.lower().split(\" \"))\n",
        "    best_match = np.argmax(scores)\n",
        "    context = df.iloc[best_match]['paragraph']\n",
        "\n",
        "    \n",
        "\n",
        "    source_encoding = tokenizer(\n",
        "        ques,\n",
        "        context,\n",
        "        max_length = self.source_max_token_len,\n",
        "        padding = \"max_length\",\n",
        "        truncation = \"only_second\",\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\")\n",
        "    \n",
        "    target_encoding = tokenizer(\n",
        "        data_row['answer'],\n",
        "        max_length = self.target_max_token_len,\n",
        "        padding = \"max_length\",\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\")\n",
        "    \n",
        "    labels = target_encoding[\"input_ids\"]\n",
        "    labels[labels == 0] = -100\n",
        "\n",
        "    return dict(\n",
        "        input_ids = source_encoding['input_ids'].flatten(),\n",
        "        attention_mask = source_encoding['attention_mask'].flatten(),\n",
        "        labels = labels.flatten())"
      ],
      "metadata": {
        "id": "jhBqD-CFACSc",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.500187Z",
          "iopub.execute_input": "2023-01-29T18:11:52.500806Z",
          "iopub.status.idle": "2023-01-29T18:11:52.511516Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.500764Z",
          "shell.execute_reply": "2023-01-29T18:11:52.510404Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset = NQADataset(df,tokenizer)"
      ],
      "metadata": {
        "id": "T_4YjQRyEat9",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.513443Z",
          "iopub.execute_input": "2023-01-29T18:11:52.513880Z",
          "iopub.status.idle": "2023-01-29T18:11:52.525111Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.513841Z",
          "shell.execute_reply": "2023-01-29T18:11:52.524011Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in sample_dataset:\n",
        "  print(data['input_ids'][:10])\n",
        "  print(data['labels'][:10])\n",
        "  break\n"
      ],
      "metadata": {
        "id": "15Hs0K2zEmGZ",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.526817Z",
          "iopub.execute_input": "2023-01-29T18:11:52.527216Z",
          "iopub.status.idle": "2023-01-29T18:11:52.548516Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.527164Z",
          "shell.execute_reply": "2023-01-29T18:11:52.547269Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(df,test_size=0.1)"
      ],
      "metadata": {
        "id": "1vPyMu7JFhZT",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.549943Z",
          "iopub.execute_input": "2023-01-29T18:11:52.550741Z",
          "iopub.status.idle": "2023-01-29T18:11:52.559380Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.550704Z",
          "shell.execute_reply": "2023-01-29T18:11:52.558403Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape, val_df.shape"
      ],
      "metadata": {
        "id": "Fx4RKkvZJuN-",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.564159Z",
          "iopub.execute_input": "2023-01-29T18:11:52.564476Z",
          "iopub.status.idle": "2023-01-29T18:11:52.572239Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.564450Z",
          "shell.execute_reply": "2023-01-29T18:11:52.571057Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NQADataModule(pl.LightningDataModule):\n",
        "  def __init__(self,train_df : pd.DataFrame,test_df : pd.DataFrame,tokenizer : Tokenizer,batch_size : int = 8,source_max_token_len : int = 400,target_max_token_len : int = 32):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "    self.tokenizer = tokenizer\n",
        "    self.source_max_token_len = source_max_token_len\n",
        "    self.target_max_token_len = target_max_token_len\n",
        "\n",
        "  def setup(self,stage=None):\n",
        "    self.train_dataset = NQADataset(self.train_df,self.tokenizer,self.source_max_token_len,self.target_max_token_len)\n",
        "    self.test_dataset = NQADataset(self.test_df,self.tokenizer,self.source_max_token_len,self.target_max_token_len)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset,batch_size = self.batch_size,shuffle=True,num_workers=4)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.test_dataset,batch_size = self.batch_size,num_workers=4)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataset,batch_size = self.batch_size,num_workers=4)   "
      ],
      "metadata": {
        "id": "Vow-rDE0JzP7",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.573492Z",
          "iopub.execute_input": "2023-01-29T18:11:52.574049Z",
          "iopub.status.idle": "2023-01-29T18:11:52.585814Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.574013Z",
          "shell.execute_reply": "2023-01-29T18:11:52.584832Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_df)"
      ],
      "metadata": {
        "id": "BPZUV0R7u7h7",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.587466Z",
          "iopub.execute_input": "2023-01-29T18:11:52.588153Z",
          "iopub.status.idle": "2023-01-29T18:11:52.599838Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.588118Z",
          "shell.execute_reply": "2023-01-29T18:11:52.598853Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 2\n",
        "N_EPOCHS = 3\n",
        "\n",
        "data_module = NQADataModule(train_df,val_df,tokenizer,batch_size = BATCH_SIZE)\n",
        "data_module.setup()"
      ],
      "metadata": {
        "id": "0CqS_ZxvPTa-",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.603114Z",
          "iopub.execute_input": "2023-01-29T18:11:52.603399Z",
          "iopub.status.idle": "2023-01-29T18:11:52.610270Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.603373Z",
          "shell.execute_reply": "2023-01-29T18:11:52.609309Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NQAModel(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.model = GPT2LMHeadModel.from_pretrained(MODEL_NAME,return_dict=True)\n",
        "    self.criterion = CrossEntropyLoss()\n",
        "\n",
        "  def forward(self,input_ids,attention_mask,labels=None):\n",
        "    output = self.model(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        labels = labels)\n",
        "    \n",
        "    return output.loss, output.logits\n",
        "\n",
        "  def training_step(self,batch,batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels = batch['labels']\n",
        "    loss = self(input_ids,attention_mask,labels)\n",
        "    self.log(\"train_loss\",loss,prog_bar=True,logger=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self,batch,batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels = batch['labels']\n",
        "    loss = self(input_ids,attention_mask,labels)\n",
        "    self.log(\"val_loss\",loss,prog_bar=True,logger=True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self,batch,batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels = batch['labels']\n",
        "    loss = self(input_ids,attention_mask,labels)\n",
        "    self.log(\"test_loss\",loss,prog_bar=True,logger=True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(),lr = 0.0001)"
      ],
      "metadata": {
        "id": "8ED4aqyfPzh0",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.611839Z",
          "iopub.execute_input": "2023-01-29T18:11:52.612404Z",
          "iopub.status.idle": "2023-01-29T18:11:52.626889Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.612370Z",
          "shell.execute_reply": "2023-01-29T18:11:52.625797Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NQAModel()"
      ],
      "metadata": {
        "id": "VPzLypoprIxC",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:11:52.628760Z",
          "iopub.execute_input": "2023-01-29T18:11:52.629074Z",
          "iopub.status.idle": "2023-01-29T18:12:28.041124Z",
          "shell.execute_reply.started": "2023-01-29T18:11:52.629042Z",
          "shell.execute_reply": "2023-01-29T18:12:28.040111Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = 'checkpoints',\n",
        "    filename = 'best_cp',\n",
        "    save_top_k = 1,\n",
        "    verbose = True,\n",
        "    monitor = 'val_loss',\n",
        "    mode = 'min'\n",
        ")"
      ],
      "metadata": {
        "id": "mc2MJG-Qrnfy",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:12:28.042873Z",
          "iopub.execute_input": "2023-01-29T18:12:28.043252Z",
          "iopub.status.idle": "2023-01-29T18:12:28.053031Z",
          "shell.execute_reply.started": "2023-01-29T18:12:28.043199Z",
          "shell.execute_reply": "2023-01-29T18:12:28.052152Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    callbacks=[checkpoint_callback],\n",
        "    max_epochs = N_EPOCHS,\n",
        "    gpus = -1\n",
        ")"
      ],
      "metadata": {
        "id": "3w3DoSKfsNa0",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:12:28.054308Z",
          "iopub.execute_input": "2023-01-29T18:12:28.054738Z",
          "iopub.status.idle": "2023-01-29T18:12:29.746231Z",
          "shell.execute_reply.started": "2023-01-29T18:12:28.054702Z",
          "shell.execute_reply": "2023-01-29T18:12:29.745188Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf checkpoints\n",
        "!rm -rf lightning_logs"
      ],
      "metadata": {
        "id": "wE2rnKHE3QCW",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:12:29.747716Z",
          "iopub.execute_input": "2023-01-29T18:12:29.748373Z",
          "iopub.status.idle": "2023-01-29T18:12:31.799403Z",
          "shell.execute_reply.started": "2023-01-29T18:12:29.748332Z",
          "shell.execute_reply": "2023-01-29T18:12:31.797999Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model,data_module)"
      ],
      "metadata": {
        "id": "XlkS5wXjsfRz",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:12:31.801788Z",
          "iopub.execute_input": "2023-01-29T18:12:31.802243Z",
          "iopub.status.idle": "2023-01-29T18:25:09.983575Z",
          "shell.execute_reply.started": "2023-01-29T18:12:31.802183Z",
          "shell.execute_reply": "2023-01-29T18:25:09.982307Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer.test(model, data_module)"
      ],
      "metadata": {
        "id": "el5jC43Pfbyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save Checkpoint to Gdrive**"
      ],
      "metadata": {
        "id": "Rb_OwNYxe-sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp -r '/content/checkpoints' '/content/drive/MyDrive/SMDM'"
      ],
      "metadata": {
        "id": "ST953oB6Y6zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the Model from chechkpoint**"
      ],
      "metadata": {
        "id": "EUalIA5gfGT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cppath = '/content/checkpoints/best_cp.ckpt'\n",
        "trained_model = NQAModel.load_from_checkpoint(cppath)\n",
        "trained_model.freeze()"
      ],
      "metadata": {
        "id": "FSVsnE8heGEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(trained_model, data_module)"
      ],
      "metadata": {
        "id": "ujCOl74vtI99",
        "execution": {
          "iopub.status.busy": "2023-01-29T18:27:53.669831Z",
          "iopub.execute_input": "2023-01-29T18:27:53.670328Z",
          "iopub.status.idle": "2023-01-29T18:28:22.545551Z",
          "shell.execute_reply.started": "2023-01-29T18:27:53.670284Z",
          "shell.execute_reply": "2023-01-29T18:28:22.544392Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Make Prediction on Sample**"
      ],
      "metadata": {
        "id": "bofkjeYBfOsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ans(ques):\n",
        "    scores = bm25.get_scores(ques.lower().split(\" \"))\n",
        "    best_match = np.argmax(scores)\n",
        "    context = df.iloc[best_match]['paragraph']\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    print(context)\n",
        "    print(\"-----------------------------------------------------------------\")\n",
        "    source_encoding = tokenizer(\n",
        "        ques,\n",
        "        context,\n",
        "        max_length = 400,\n",
        "        padding = \"max_length\",\n",
        "        truncation = \"only_second\",\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\")\n",
        "    \n",
        "    generated_ids = trained_model.model.generate(\n",
        "        input_ids = source_encoding['input_ids'],\n",
        "        attention_mask = source_encoding['attention_mask'],\n",
        "        num_beams = 1,\n",
        "        max_length = 32,\n",
        "        repetition_penalty = 2.5,\n",
        "        length_penalty = 1.0,\n",
        "        early_stopping = True,\n",
        "        use_cache = True)\n",
        "    \n",
        "    preds = [\n",
        "        tokenizer.decode(generated_id,skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "        for generated_id in generated_ids]\n",
        "    \n",
        "    return \" \".join(preds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-29T19:10:17.673965Z",
          "iopub.execute_input": "2023-01-29T19:10:17.674389Z",
          "iopub.status.idle": "2023-01-29T19:10:17.681670Z",
          "shell.execute_reply.started": "2023-01-29T19:10:17.674355Z",
          "shell.execute_reply": "2023-01-29T19:10:17.680559Z"
        },
        "trusted": true,
        "id": "5j_9yzO1CjSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_question = val_df.iloc[10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-29T19:10:18.554993Z",
          "iopub.execute_input": "2023-01-29T19:10:18.555394Z",
          "iopub.status.idle": "2023-01-29T19:10:18.560285Z",
          "shell.execute_reply.started": "2023-01-29T19:10:18.555362Z",
          "shell.execute_reply": "2023-01-29T19:10:18.559190Z"
        },
        "trusted": true,
        "id": "uRADVi88CjSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_question['question']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-29T19:10:19.425496Z",
          "iopub.execute_input": "2023-01-29T19:10:19.425870Z",
          "iopub.status.idle": "2023-01-29T19:10:19.435511Z",
          "shell.execute_reply.started": "2023-01-29T19:10:19.425840Z",
          "shell.execute_reply": "2023-01-29T19:10:19.434380Z"
        },
        "trusted": true,
        "id": "OK8aDfgBCjSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_question['answer']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-29T19:10:20.188881Z",
          "iopub.execute_input": "2023-01-29T19:10:20.189274Z",
          "iopub.status.idle": "2023-01-29T19:10:20.196866Z",
          "shell.execute_reply.started": "2023-01-29T19:10:20.189241Z",
          "shell.execute_reply": "2023-01-29T19:10:20.195420Z"
        },
        "trusted": true,
        "id": "cLqEiT6WCjSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_question['paragraph']"
      ],
      "metadata": {
        "id": "Y7QUR6PuuJei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_ans(sample_question['question'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-29T19:10:21.466997Z",
          "iopub.execute_input": "2023-01-29T19:10:21.467749Z",
          "iopub.status.idle": "2023-01-29T19:10:23.030908Z",
          "shell.execute_reply.started": "2023-01-29T19:10:21.467713Z",
          "shell.execute_reply": "2023-01-29T19:10:23.029880Z"
        },
        "trusted": true,
        "id": "IGufqPQKCjSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strng = 'Who taught Jaar to turn her singing back inwards?'\n",
        "generate_ans(strng)"
      ],
      "metadata": {
        "id": "dc6x4i7r0tw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8moWOCR07dz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}